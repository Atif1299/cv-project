# ğŸ–¼ï¸ Image Captioning - Deep Learning Project

> **AI-powered Image Caption Generator using Xception CNN + LSTM**

[![Deploy to Cloud Run](https://img.shields.io/badge/Deploy%20to-Cloud%20Run-blue.svg)](https://cloud.google.com/run)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://tensorflow.org)

---

## ğŸ¯ Project Overview

This is a deep learning-based **Image Captioning** system that generates natural language descriptions for images. Built as part of NLP Assignment 4 (SP23-BAI-035, SP23-BAI-031, SP23-BAI-042).

### Key Features
- ğŸ§  **Xception CNN** for image feature extraction
- ğŸ“ **LSTM** for sequential caption generation
- ğŸŒ **Flask Web App** with modern UI
- â˜ï¸ **Cloud-Ready** - Deploy to GCP Cloud Run in minutes
- ğŸš€ **Auto-scaling** production-ready deployment

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Image     â”‚
â”‚  (299x299)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Xception CNN    â”‚
â”‚  (Pre-trained)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (2048 features)
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                      â”‚
       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dense     â”‚      â”‚  Embedding  â”‚
â”‚   (256)     â”‚      â”‚  + LSTM     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
       â””â”€â”€â”€â–ºâ”‚  Merge   â”‚â—„â”€â”€â”€â”˜
            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Dense (7577) â”‚
         â”‚   (Softmax)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
           Caption Word
```

**Model Components:**
- **Encoder:** Xception (ImageNet pre-trained)
- **Decoder:** LSTM with Embedding layer
- **Vocabulary:** 7,577 words
- **Max Caption Length:** 34 words
- **Dataset:** Flickr8k (6,000 training images)

---

## ğŸš€ Quick Deploy to GCP Cloud Run

### Option 1: One-Command Deploy (Fastest)
```bash
gcloud run deploy image-captioning-app \
  --source ./app/app \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 4Gi \
  --cpu 2
```

### Option 2: Auto-Deploy from GitHub
1. Connect your GitHub repo to Cloud Build
2. Push to `main` branch â†’ **Auto-deploys!**

ğŸ“– **Detailed Guide:** See [QUICK_START.md](QUICK_START.md) or [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)

---

## ğŸ’» Local Development

### Prerequisites
- Python 3.10+
- pip

### Setup
```bash
# 1. Clone repository
git clone <your-repo-url>
cd CV

# 2. Install dependencies
cd app/app
pip install -r requirements.txt

# 3. Run locally
python app.py

# 4. Open browser
# http://localhost:5000
```

---

## ğŸ“ Project Structure

```
CV/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ app.py                 # Flask application
â”‚       â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚       â”œâ”€â”€ Dockerfile            # Docker configuration
â”‚       â”œâ”€â”€ .dockerignore         # Docker ignore rules
â”‚       â”œâ”€â”€ saved/
â”‚       â”‚   â”œâ”€â”€ model_5.h5        # Trained model weights
â”‚       â”‚   â””â”€â”€ tokenizer.p       # Text tokenizer
â”‚       â””â”€â”€ templates/
â”‚           â””â”€â”€ index.html        # Web UI
â”œâ”€â”€ main.ipynb                    # Training notebook
â”œâ”€â”€ cloudbuild.yaml               # GCP Cloud Build config
â”œâ”€â”€ deploy.sh                     # Deployment script
â”œâ”€â”€ QUICK_START.md               # Quick deployment guide
â”œâ”€â”€ DEPLOYMENT_GUIDE.md          # Detailed deployment guide
â””â”€â”€ README.md                    # This file
```

---

## ğŸ§ª API Usage

### Web Interface
Upload an image at `http://your-url/`

### REST API
```bash
curl -X POST http://your-url/predict \
  -F "image=@path/to/image.jpg"
```

**Response:**
```json
{
  "caption": "a dog is running in the grass"
}
```

---

## ğŸ“Š Model Performance

- **Training Dataset:** Flickr8k (6,000 images)
- **Training Loss:** 4.46 â†’ 3.01 (40 epochs)
- **Architecture:** Encoder-Decoder with Attention
- **Feature Dimension:** 2048 â†’ 256
- **LSTM Units:** 256

---

## ğŸ”§ Configuration

### Resource Requirements
- **Memory:** 4GB RAM (minimum)
- **CPU:** 2 vCPUs (recommended)
- **Storage:** ~1GB (model + dependencies)

### Environment Variables
```bash
PORT=8080                    # Server port
PYTHONUNBUFFERED=1          # Enable Python logging
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Backend** | Flask (Python) |
| **ML Framework** | TensorFlow/Keras |
| **CNN Model** | Xception |
| **RNN Model** | LSTM |
| **Frontend** | HTML, Bootstrap 5, JavaScript |
| **Deployment** | Docker, GCP Cloud Run |
| **CI/CD** | Cloud Build (optional) |

---

## ğŸ“ˆ Deployment Options

1. **GCP Cloud Run** (Recommended)
   - Auto-scaling
   - Pay-per-use
   - HTTPS included
   - Free tier available

2. **Docker Container**
   ```bash
   docker build -t image-captioning ./app/app
   docker run -p 8080:8080 image-captioning
   ```

3. **Local Flask Server**
   ```bash
   python app.py
   ```

---

## ğŸ’° Cost Estimate (GCP Cloud Run)

- **Free Tier:** 2 million requests/month
- **Beyond Free Tier:** ~$0.20-0.50/hour (only when serving)
- **No idle costs** - scales to zero when not in use

---

## ğŸ“ Academic Context

**Course:** Natural Language Processing (NLP)  
**Assignment:** A4 - Image Captioning  
**Team Members:**
- SP23-BAI-035
- SP23-BAI-031
- SP23-BAI-042

**Model Approach:**
- Image feature extraction using transfer learning (Xception)
- Sequence-to-sequence caption generation (LSTM)
- Teacher forcing during training
- Greedy decoding during inference

---

## ğŸ¤ Contributing

Feel free to fork this repository and submit pull requests for improvements!

---

## ğŸ“„ License

This project is for academic purposes.

---

## ğŸ†˜ Troubleshooting

### Issue: Out of Memory
```bash
# Increase memory allocation
gcloud run services update image-captioning-app --memory 8Gi
```

### Issue: Slow Response
- First request after idle may take 15-30 seconds (cold start)
- Consider setting `--min-instances 1` for production

### Issue: Deployment Fails
- Check model files are included in repository
- Ensure `saved/model_5.h5` exists
- Verify all dependencies in requirements.txt

---

## ğŸ“ Support

For deployment issues, check:
- [QUICK_START.md](QUICK_START.md) - Fast setup
- [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) - Detailed guide
- [GCP Cloud Run Docs](https://cloud.google.com/run/docs)

---

## â­ Show Your Support

If this project helped you, please give it a star! â­

---

**Built with â¤ï¸ using TensorFlow and Flask**

